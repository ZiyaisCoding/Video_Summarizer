{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\01_Ziya\\01_CS\\03_Projects\\Minor_Project\\minpro\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video data\n",
    "# cap = cv2.VideoCapture('vid1.mp4')\n",
    "# Load .npy video files\n",
    "video = np.load('01_Data/Air_Force_One.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    # Preprocess frame here (e.g., resize, normalize)\n",
    "    frame = cv2.resize(frame, (128, 128))  # Resize to match the expected input shape\n",
    "    frame = frame.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess frames\n",
    "video_data = np.array([preprocess_frame(frame) for frame in video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966080160"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frames to numpy array\n",
    "# video_data = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Convolutional Autoencoder model\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(128, 128, 3)),  # Assuming color frames\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(4, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(8, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\01_Ziya\\01_CS\\03_Projects\\Minor_Project\\minpro\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\01_Ziya\\01_CS\\03_Projects\\Minor_Project\\minpro\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the convolutional autoencoder\n",
    "latent_dim = 64\n",
    "conv_autoencoder = ConvAutoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\01_Ziya\\01_CS\\03_Projects\\Minor_Project\\minpro\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "conv_autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\01_Ziya\\01_CS\\03_Projects\\Minor_Project\\minpro\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "313/313 [==============================] - 180s 568ms/step - loss: 0.0254\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 172s 549ms/step - loss: 0.0014\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 175s 558ms/step - loss: 0.0011\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 169s 538ms/step - loss: 9.3423e-04\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 165s 527ms/step - loss: 9.5464e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x246e4f49890>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "conv_autoencoder.fit(video_data, video_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the summarization loop to skip frames\n",
    "skip_factor = 1 # Change this value to adjust the frame rate\n",
    "summarized_frames = []\n",
    "for i, frame in enumerate(video_data):\n",
    "    if i % skip_factor == 0:  # Skip frames based on the skip_factor\n",
    "        encoded_frame = conv_autoencoder.encoder(np.expand_dims(frame, axis=0)).numpy()\n",
    "        decoded_frame = conv_autoencoder.decoder(encoded_frame).numpy()[0]\n",
    "        summarized_frames.append(decoded_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summarized video in MP4 format\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')  # Define MP4 codec\n",
    "out = cv2.VideoWriter('summarized_video2.mp4', fourcc, 60.0, (128, 128), isColor=True)  # Set isColor=False for grayscale video\n",
    "\n",
    "for frame in summarized_frames:\n",
    "    # Ensure frame is in uint8 format\n",
    "    frame_uint8 = (frame * 255).astype(np.uint8)\n",
    "    # Resize the frame to match output dimensions\n",
    "    frame_resized = cv2.resize(frame_uint8, (128, 128))\n",
    "    out.write(frame_resized)\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of reconstructing a frame\n",
    "encoded_frame = conv_autoencoder.encoder(np.expand_dims(video_data[0], axis=0)).numpy()\n",
    "decoded_frame = conv_autoencoder.decoder(encoded_frame).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize original frame for better visualization\n",
    "original_height, original_width, _ = video_data[0].shape\n",
    "original_frame_resized = cv2.resize(video_data[0], (original_width * 10, original_height * 10))\n",
    "\n",
    "# Resize reconstructed frame for better visualization\n",
    "decoded_frame_resized = cv2.resize(decoded_frame[0], (original_width * 10, original_height * 10))\n",
    "\n",
    "# Display original and resized reconstructed frame\n",
    "# cv2.imshow('Original Frame', original_frame_resized)\n",
    "# cv2.imshow('Reconstructed Frame', decoded_frame_resized)\n",
    "# cv2.waitKey(0) \n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through frames and display original and reconstructed frames\n",
    "for i in range(len(video_data)):\n",
    "    original_frame = video_data[i]\n",
    "\n",
    "    # Reconstruct frame\n",
    "    encoded_frame = conv_autoencoder.encoder(np.expand_dims(original_frame, axis=0)).numpy()\n",
    "    reconstructed_frame = conv_autoencoder.decoder(encoded_frame).numpy()[0]\n",
    "\n",
    "    # Resize frames for better visualization\n",
    "    original_frame_resized = cv2.resize(original_frame, (original_width * 20, original_height * 20))\n",
    "    reconstructed_frame_resized = cv2.resize(reconstructed_frame, (original_width * 20, original_height * 20))\n",
    "\n",
    "    # Display original and reconstructed frames\n",
    "    cv2.imshow('Original Frame', original_frame_resized)\n",
    "    cv2.imshow('Reconstructed Frame', reconstructed_frame_resized)\n",
    "    cv2.waitKey(10)  # Adjust delay between frames (in milliseconds) as needed\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
