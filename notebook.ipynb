{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2a94ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T05:54:33.605069Z",
     "iopub.status.busy": "2024-04-27T05:54:33.604104Z",
     "iopub.status.idle": "2024-04-27T05:54:47.359938Z",
     "shell.execute_reply": "2024-04-27T05:54:47.359164Z"
    },
    "papermill": {
     "duration": 13.765169,
     "end_time": "2024-04-27T05:54:47.362369",
     "exception": false,
     "start_time": "2024-04-27T05:54:33.597200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e242e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T05:54:47.374189Z",
     "iopub.status.busy": "2024-04-27T05:54:47.373666Z",
     "iopub.status.idle": "2024-04-27T05:54:47.381868Z",
     "shell.execute_reply": "2024-04-27T05:54:47.381065Z"
    },
    "papermill": {
     "duration": 0.016011,
     "end_time": "2024-04-27T05:54:47.383825",
     "exception": false,
     "start_time": "2024-04-27T05:54:47.367814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load frames from videos in a directory\n",
    "def load_frames_from_directory(directory_path, frame_interval=1, target_size=(128,128)):\n",
    "    video_files = [f for f in os.listdir(directory_path) if f.lower().endswith(('.mp4', '.avi', '.mov'))]\n",
    "    frames = []\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(directory_path, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()  # Read a frame\n",
    "            if not ret:\n",
    "                break  # If no more frames, exit loop\n",
    "\n",
    "            if frame_count % frame_interval == 0:\n",
    "                frame = cv2.resize(frame, target_size)  # Resize frame\n",
    "                frame = frame.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "                frames.append(frame)  # Store preprocessed frame\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()  # Release the video capture\n",
    "\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36784c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T05:54:47.395093Z",
     "iopub.status.busy": "2024-04-27T05:54:47.394635Z",
     "iopub.status.idle": "2024-04-27T05:54:47.406675Z",
     "shell.execute_reply": "2024-04-27T05:54:47.405871Z"
    },
    "papermill": {
     "duration": 0.019658,
     "end_time": "2024-04-27T05:54:47.408444",
     "exception": false,
     "start_time": "2024-04-27T05:54:47.388786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the Convolutional Autoencoder class\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "\n",
    "        # Define the encoder\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(128,128, 3)),  # Correctly set the input shape\n",
    "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        ])\n",
    "\n",
    "        # Bottleneck with a Dense layer\n",
    "        self.bottleneck = tf.keras.Sequential([\n",
    "            layers.Flatten(),  # Flatten the encoder output\n",
    "            layers.Dense(latent_dim)  # Dense layer with the latent dimension\n",
    "        ])\n",
    "\n",
    "        # Define the decoder\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(latent_dim,)),  # This accepts a 1D latent space\n",
    "            layers.Reshape((1, 1, latent_dim)),  # Reshape back to 2D for transposed conv\n",
    "            layers.Conv2DTranspose(4, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(8, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(256, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same'),  # Final output layer\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # Encode the input\n",
    "        encoded = self.encoder(x)\n",
    "        # Get the latent representation\n",
    "        latent_representation = self.bottleneck(encoded)\n",
    "        # Decode to reconstruct the input\n",
    "        decoded = self.decoder(latent_representation)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d580bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T05:54:47.419198Z",
     "iopub.status.busy": "2024-04-27T05:54:47.418963Z",
     "iopub.status.idle": "2024-04-27T05:54:48.319372Z",
     "shell.execute_reply": "2024-04-27T05:54:48.318446Z"
    },
    "papermill": {
     "duration": 0.908023,
     "end_time": "2024-04-27T05:54:48.321319",
     "exception": false,
     "start_time": "2024-04-27T05:54:47.413296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the ConvAutoencoder model with a latent dimension\n",
    "latent_dim = 64\n",
    "model = ConvAutoencoder(latent_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68fb7d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:43:15.800546Z",
     "iopub.status.busy": "2024-04-26T18:43:15.799585Z",
     "iopub.status.idle": "2024-04-26T18:46:13.121819Z",
     "shell.execute_reply": "2024-04-26T18:46:13.121015Z",
     "shell.execute_reply.started": "2024-04-26T18:43:15.800504Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load frames from a directory with multiple video files\n",
    "video_directory = 'E:\\DeltaMod\\Data'  # Your video directory\n",
    "frame_interval = 10\n",
    "training_data = load_frames_from_directory(video_directory, frame_interval=frame_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7582a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T19:58:03.329956Z",
     "iopub.status.busy": "2024-04-24T19:58:03.329539Z",
     "iopub.status.idle": "2024-04-24T19:58:03.335241Z",
     "shell.execute_reply": "2024-04-24T19:58:03.333970Z",
     "shell.execute_reply.started": "2024-04-24T19:58:03.329924Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure there's data to train on\n",
    "if len(training_data) == 0:\n",
    "    raise ValueError(\"No frames loaded from the specified directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89e3421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T19:58:05.299290Z",
     "iopub.status.busy": "2024-04-24T19:58:05.298902Z",
     "iopub.status.idle": "2024-04-24T19:58:05.306264Z",
     "shell.execute_reply": "2024-04-24T19:58:05.305131Z",
     "shell.execute_reply.started": "2024-04-24T19:58:05.299261Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733099520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181a35df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T19:58:09.573416Z",
     "iopub.status.busy": "2024-04-24T19:58:09.572977Z",
     "iopub.status.idle": "2024-04-24T19:58:11.532525Z",
     "shell.execute_reply": "2024-04-24T19:58:11.531371Z",
     "shell.execute_reply.started": "2024-04-24T19:58:09.573376Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets\n",
    "train_data, val_data = train_test_split(training_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7283e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Ensure TensorFlow is using the GPU\n",
    "tf.debugging.set_log_device_placement(True)  # Enable device placement logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ecf7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28208, 128, 128, 3) float32\n",
      "(7052, 128, 128, 3) float32\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, train_data.dtype)\n",
    "print(val_data.shape, val_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1a7adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  4 12:35:09 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.49       Driver Version: 528.49       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000    WDDM  | 00000000:61:00.0 Off |                  Off |\n",
      "| 35%   46C    P8     7W / 230W |  15962MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      9184    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A      9604    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A      9632    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     12624    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12740    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12792    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13492    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     13936    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14164    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A     16012    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     18648    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19076      C   ...ant3\\anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     23884      C   ...ant3\\anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up the data augmentation generator\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=10,         # Stop if no improvement for 10 epochs\n",
    "    verbose=1,           # Output early stopping messages\n",
    "    restore_best_weights=True  # Restore the best model weights\n",
    ")\n",
    "\n",
    "# Train the model with the early stopping callback\n",
    "model.fit(\n",
    "    data_gen.flow(train_data, train_data, batch_size=4), \n",
    "    validation_data=data_gen.flow(val_data, val_data),\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping]  # Include early stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4d12a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:49:05.458097Z",
     "iopub.status.busy": "2024-04-26T18:49:05.457351Z",
     "iopub.status.idle": "2024-04-26T18:49:05.501560Z",
     "shell.execute_reply": "2024-04-26T18:49:05.500407Z",
     "shell.execute_reply.started": "2024-04-26T18:49:05.458065Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Layers:\n",
      "Layer 1: Conv2D\n",
      " - Output shape: (None, 128, 128, 128)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 2: MaxPooling2D\n",
      " - Output shape: (None, 64, 64, 128)\n",
      " - Activation: None\n",
      "Layer 3: Conv2D\n",
      " - Output shape: (None, 64, 64, 64)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 4: MaxPooling2D\n",
      " - Output shape: (None, 32, 32, 64)\n",
      " - Activation: None\n",
      "Layer 5: Conv2D\n",
      " - Output shape: (None, 32, 32, 32)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 6: MaxPooling2D\n",
      " - Output shape: (None, 16, 16, 32)\n",
      " - Activation: None\n",
      "Layer 7: Conv2D\n",
      " - Output shape: (None, 16, 16, 16)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 8: MaxPooling2D\n",
      " - Output shape: (None, 8, 8, 16)\n",
      " - Activation: None\n",
      "Layer 9: Conv2D\n",
      " - Output shape: (None, 8, 8, 8)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 10: MaxPooling2D\n",
      " - Output shape: (None, 4, 4, 8)\n",
      " - Activation: None\n",
      "\n",
      "Bottleneck Layers:\n",
      "Layer 1: Flatten\n",
      " - Output shape: (None, 128)\n",
      " - Activation: None\n",
      "Layer 2: Dense\n",
      " - Output shape: (None, 64)\n",
      " - Activation: <function linear at 0x0000020A9A79DEE0>\n",
      "\n",
      "Decoder Layers:\n",
      "Layer 1: Reshape\n",
      " - Output shape: (None, 1, 1, 64)\n",
      " - Activation: None\n",
      "Layer 2: Conv2DTranspose\n",
      " - Output shape: (None, 2, 2, 4)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 3: Conv2DTranspose\n",
      " - Output shape: (None, 4, 4, 8)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 4: Conv2DTranspose\n",
      " - Output shape: (None, 8, 8, 16)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 5: Conv2DTranspose\n",
      " - Output shape: (None, 16, 16, 32)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 6: Conv2DTranspose\n",
      " - Output shape: (None, 32, 32, 64)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 7: Conv2DTranspose\n",
      " - Output shape: (None, 64, 64, 128)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 8: Conv2DTranspose\n",
      " - Output shape: (None, 128, 128, 256)\n",
      " - Activation: <function relu at 0x0000020A9A79D4C0>\n",
      "Layer 9: Conv2D\n",
      " - Output shape: (None, 128, 128, 3)\n",
      " - Activation: <function sigmoid at 0x0000020A9A79D9D0>\n"
     ]
    }
   ],
   "source": [
    "# Details of encoder layers\n",
    "print(\"Encoder Layers:\")\n",
    "for i, layer in enumerate(model.encoder.layers):\n",
    "    print(f\"Layer {i + 1}: {layer.__class__.__name__}\")\n",
    "    print(f\" - Output shape: {layer.output_shape}\")  # Now this should work\n",
    "    print(f\" - Activation: {layer.activation if hasattr(layer, 'activation') else 'None'}\")\n",
    "\n",
    "# Details of bottleneck layers\n",
    "print(\"\\nBottleneck Layers:\")\n",
    "for i, layer in enumerate(model.bottleneck.layers):\n",
    "    print(f\"Layer {i + 1}: {layer.__class__.__name__}\")\n",
    "    print(f\" - Output shape: {layer.output_shape}\")\n",
    "    print(f\" - Activation: {layer.activation if hasattr(layer, 'activation') else 'None'}\")\n",
    "\n",
    "# Details of decoder layers\n",
    "print(\"\\nDecoder Layers:\")\n",
    "for i, layer in enumerate(model.decoder.layers):\n",
    "    print(f\"Layer {i + 1}: {layer.__class__.__name__}\")\n",
    "    print(f\" - Output shape: {layer.output_shape}\")\n",
    "    print(f\" - Activation: {layer.activation if hasattr(layer, 'activation') else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "148f8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\DeltaMod\\Data\\model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\DeltaMod\\Data\\model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('E:\\DeltaMod\\Data\\model')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3292270,
     "sourceId": 5724982,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4549962,
     "sourceId": 8188293,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.279665,
   "end_time": "2024-04-27T05:54:51.907436",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-27T05:54:30.627771",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
